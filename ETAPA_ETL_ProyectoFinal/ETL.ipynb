{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“Š Proceso ETL - AnÃ¡lisis de Pedidos Entregados de Olist\n",
        "\n",
        "## ğŸ¯ Objetivo del Proyecto\n",
        "Este notebook implementa un pipeline ETL (Extract, Transform, Load) robusto para consolidar mÃºltiples fuentes de datos del ecosistema Olist en una tabla analÃ­tica unificada.\n",
        "\n",
        "**Historia de Negocio:**\n",
        "Olist es una plataforma de e-commerce brasileÃ±a que conecta pequeÃ±as empresas con grandes marketplaces. Para maximizar el valor de los datos, necesitamos:\n",
        "1. **Integrar** informaciÃ³n dispersa en 6 datasets diferentes\n",
        "2. **Filtrar** Ãºnicamente pedidos completados exitosamente (status='delivered')\n",
        "3. **Generar** una tabla maestra que permita anÃ¡lisis estratÃ©gicos\n",
        "\n",
        "**Resultado esperado:** Un dataset consolidado que responda preguntas como:\n",
        "- Â¿QuÃ© categorÃ­as de productos generan mejores reviews?\n",
        "- Â¿CuÃ¡l es la preferencia de pago por estado?\n",
        "- Â¿CÃ³mo se relaciona el precio con la satisfacciÃ³n del cliente?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ Paso 1: ImportaciÃ³n de LibrerÃ­as\n",
        "\n",
        "Utilizamos las herramientas esenciales del ecosistema Python para data engineering:\n",
        "- **pandas**: ManipulaciÃ³n y transformaciÃ³n de datos tabulares\n",
        "- **numpy**: Operaciones numÃ©ricas optimizadas\n",
        "- **warnings**: GestiÃ³n de alertas durante el proceso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LibrerÃ­as cargadas exitosamente\n",
            "ğŸ“… Fecha de ejecuciÃ³n: 2026-01-21 14:09:31\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# ConfiguraciÃ³n del entorno\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)  # Visualizar todas las columnas\n",
        "pd.set_option('display.width', None)        # Sin lÃ­mite de ancho\n",
        "\n",
        "print(\"âœ… LibrerÃ­as cargadas exitosamente\")\n",
        "print(f\"ğŸ“… Fecha de ejecuciÃ³n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ Paso 2: EXTRACT - Carga de Datos Fuente\n",
        "\n",
        "**Estrategia de ExtracciÃ³n:**\n",
        "Cargamos 6 datasets crÃ­ticos del ecosistema Olist. Cada archivo representa una dimensiÃ³n del negocio:\n",
        "\n",
        "| Dataset | Rol en el Negocio | Granularidad |\n",
        "|---------|-------------------|-------------|\n",
        "| Orders | Transacciones principales | 1 fila = 1 pedido |\n",
        "| Customers | Datos demogrÃ¡ficos | 1 fila = 1 cliente |\n",
        "| Order Items | Detalle de productos | 1 fila = 1 Ã­tem en pedido |\n",
        "| Payments | InformaciÃ³n financiera | 1 fila = 1 pago (puede haber mÃºltiples) |\n",
        "| Reviews | SatisfacciÃ³n del cliente | 1 fila = 1 reseÃ±a |\n",
        "| Products | CatÃ¡logo de productos | 1 fila = 1 producto Ãºnico |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… orders          | Filas: 99,441 | Columnas: 8\n",
            "âœ… customers       | Filas: 99,441 | Columnas: 5\n",
            "âœ… order_items     | Filas: 112,650 | Columnas: 7\n",
            "âœ… payments        | Filas: 103,886 | Columnas: 5\n",
            "âœ… reviews         | Filas: 99,224 | Columnas: 7\n",
            "âœ… products        | Filas: 32,951 | Columnas: 9\n",
            "\n",
            "ğŸ“Š Total de datasets cargados: 6/6\n"
          ]
        }
      ],
      "source": [
        "# DefiniciÃ³n de rutas de archivos\n",
        "archivos = {\n",
        "    'orders': 'olist_orders_dataset.csv',\n",
        "    'customers': 'olist_customers_dataset.csv',\n",
        "    'order_items': 'olist_order_items_dataset.csv',\n",
        "    'payments': 'olist_order_payments_dataset.csv',\n",
        "    'reviews': 'olist_order_reviews_dataset.csv',\n",
        "    'products': 'olist_products_dataset.csv'\n",
        "}\n",
        "\n",
        "# Carga de datasets con manejo de errores\n",
        "dataframes = {}\n",
        "\n",
        "for nombre, archivo in archivos.items():\n",
        "    try:\n",
        "        df = pd.read_csv(archivo)\n",
        "        dataframes[nombre] = df\n",
        "        print(f\"âœ… {nombre:15} | Filas: {len(df):,} | Columnas: {len(df.columns)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"âŒ ERROR: No se encontrÃ³ el archivo {archivo}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ERROR en {archivo}: {str(e)}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Total de datasets cargados: {len(dataframes)}/6\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” Paso 3: ExploraciÃ³n Inicial de Datos\n",
        "\n",
        "Antes de transformar, entendemos la estructura y calidad de nuestros datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ“‹ REPORTE DE CALIDAD DE DATOS\n",
            "================================================================================\n",
            "\n",
            "ğŸ”¹ ORDERS\n",
            "   Dimensiones: 99,441 filas Ã— 8 columnas\n",
            "   Memoria: 58.97 MB\n",
            "   âš ï¸  Valores nulos detectados:\n",
            "      - order_approved_at: 160 (0.2%)\n",
            "      - order_delivered_carrier_date: 1,783 (1.8%)\n",
            "      - order_delivered_customer_date: 2,965 (3.0%)\n",
            "\n",
            "ğŸ”¹ CUSTOMERS\n",
            "   Dimensiones: 99,441 filas Ã— 5 columnas\n",
            "   Memoria: 29.62 MB\n",
            "   âœ… Sin valores nulos\n",
            "\n",
            "ğŸ”¹ ORDER_ITEMS\n",
            "   Dimensiones: 112,650 filas Ã— 7 columnas\n",
            "   Memoria: 39.43 MB\n",
            "   âœ… Sin valores nulos\n",
            "\n",
            "ğŸ”¹ PAYMENTS\n",
            "   Dimensiones: 103,886 filas Ã— 5 columnas\n",
            "   Memoria: 17.81 MB\n",
            "   âœ… Sin valores nulos\n",
            "\n",
            "ğŸ”¹ REVIEWS\n",
            "   Dimensiones: 99,224 filas Ã— 7 columnas\n",
            "   Memoria: 42.75 MB\n",
            "   âš ï¸  Valores nulos detectados:\n",
            "      - review_comment_title: 87,656 (88.3%)\n",
            "      - review_comment_message: 58,247 (58.7%)\n",
            "\n",
            "ğŸ”¹ PRODUCTS\n",
            "   Dimensiones: 32,951 filas Ã— 9 columnas\n",
            "   Memoria: 6.79 MB\n",
            "   âš ï¸  Valores nulos detectados:\n",
            "      - product_category_name: 610 (1.9%)\n",
            "      - product_name_lenght: 610 (1.9%)\n",
            "      - product_description_lenght: 610 (1.9%)\n",
            "      - product_photos_qty: 610 (1.9%)\n",
            "      - product_weight_g: 2 (0.0%)\n",
            "      - product_length_cm: 2 (0.0%)\n",
            "      - product_height_cm: 2 (0.0%)\n",
            "      - product_width_cm: 2 (0.0%)\n",
            "\n",
            "================================================================================\n",
            "ğŸ‘€ DISTRIBUCIÃ“N DE STATUS EN ORDERS\n",
            "================================================================================\n",
            "order_status\n",
            "delivered      96478\n",
            "shipped         1107\n",
            "canceled         625\n",
            "unavailable      609\n",
            "invoiced         314\n",
            "processing       301\n",
            "created            5\n",
            "approved           2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ğŸ“Œ Filtraremos Ãºnicamente pedidos con status = 'delivered'\n"
          ]
        }
      ],
      "source": [
        "# AnÃ¡lisis de calidad de datos\n",
        "print(\"=\" * 80)\n",
        "print(\"ğŸ“‹ REPORTE DE CALIDAD DE DATOS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for nombre, df in dataframes.items():\n",
        "    print(f\"\\nğŸ”¹ {nombre.upper()}\")\n",
        "    print(f\"   Dimensiones: {df.shape[0]:,} filas Ã— {df.shape[1]} columnas\")\n",
        "    print(f\"   Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Valores nulos\n",
        "    nulos = df.isnull().sum()\n",
        "    if nulos.sum() > 0:\n",
        "        print(f\"   âš ï¸  Valores nulos detectados:\")\n",
        "        for col, count in nulos[nulos > 0].items():\n",
        "            print(f\"      - {col}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"   âœ… Sin valores nulos\")\n",
        "\n",
        "# Vista previa del dataset de orders (crÃ­tico para filtrado)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ‘€ DISTRIBUCIÃ“N DE STATUS EN ORDERS\")\n",
        "print(\"=\" * 80)\n",
        "print(dataframes['orders']['order_status'].value_counts())\n",
        "print(f\"\\nğŸ“Œ Filtraremos Ãºnicamente pedidos con status = 'delivered'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Paso 4: TRANSFORM - Filtrado y Limpieza\n",
        "\n",
        "**DecisiÃ³n EstratÃ©gica de Negocio:**\n",
        "Nos enfocamos en pedidos **entregados exitosamente** porque:\n",
        "1. Representan transacciones completas (revenue real)\n",
        "2. Tienen reviews vÃ¡lidas (feedback genuino)\n",
        "3. Reflejan la experiencia completa del cliente\n",
        "\n",
        "Pedidos cancelados, en proceso o con problemas se excluyen para mantener la integridad analÃ­tica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Aplicando filtro de status...\n",
            "\n",
            "ğŸ“Š Pedidos originales:  99,441\n",
            "âœ… Pedidos delivered:   96,478\n",
            "âŒ Pedidos excluidos:   2,963\n",
            "ğŸ“ˆ Tasa de entrega:     97.02%\n"
          ]
        }
      ],
      "source": [
        "# FILTRO 1: Orders con status 'delivered'\n",
        "print(\"ğŸ”„ Aplicando filtro de status...\\n\")\n",
        "\n",
        "orders_original = len(dataframes['orders'])\n",
        "orders_delivered = dataframes['orders'][dataframes['orders']['order_status'] == 'delivered'].copy()\n",
        "orders_filtrados = len(orders_delivered)\n",
        "\n",
        "print(f\"ğŸ“Š Pedidos originales:  {orders_original:,}\")\n",
        "print(f\"âœ… Pedidos delivered:   {orders_filtrados:,}\")\n",
        "print(f\"âŒ Pedidos excluidos:   {orders_original - orders_filtrados:,}\")\n",
        "print(f\"ğŸ“ˆ Tasa de entrega:     {orders_filtrados/orders_original*100:.2f}%\")\n",
        "\n",
        "# Almacenar el dataset filtrado\n",
        "dataframes['orders_delivered'] = orders_delivered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”— Paso 5: TRANSFORM - ConstrucciÃ³n de Tabla Maestra\n",
        "\n",
        "**Arquitectura de Joins:**\n",
        "\n",
        "```\n",
        "                    ORDERS (delivered)\n",
        "                          |\n",
        "         +----------------+----------------+\n",
        "         |                |                |\n",
        "    CUSTOMERS        ORDER_ITEMS       REVIEWS\n",
        "                          |\n",
        "                     PRODUCTS\n",
        "                          |\n",
        "                      PAYMENTS\n",
        "```\n",
        "\n",
        "**Estrategia:**\n",
        "- **Left joins** para preservar todos los pedidos delivered\n",
        "- AgregaciÃ³n de payments (un pedido puede tener mÃºltiples pagos)\n",
        "- AgregaciÃ³n de reviews (priorizar la primera reseÃ±a por pedido)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ Preparando datasets para merge...\n",
            "\n",
            "âœ… Payments agregado: 103,886 registros â†’ 99,440 pedidos Ãºnicos\n",
            "âœ… Reviews procesado:  99,224 registros â†’ 98,673 pedidos Ãºnicos\n"
          ]
        }
      ],
      "source": [
        "# PASO 5.1: PreparaciÃ³n de datasets auxiliares\n",
        "print(\"ğŸ”§ Preparando datasets para merge...\\n\")\n",
        "\n",
        "# AgregaciÃ³n de PAYMENTS: Consolidar mÃºltiples pagos por order_id\n",
        "# Estrategia: Tomamos el tipo de pago mÃ¡s comÃºn (moda) por pedido\n",
        "payments_agg = dataframes['payments'].groupby('order_id').agg({\n",
        "    'payment_type': lambda x: x.mode()[0] if not x.mode().empty else x.iloc[0],\n",
        "    'payment_value': 'sum'  # Suma total de pagos\n",
        "}).reset_index()\n",
        "\n",
        "print(f\"âœ… Payments agregado: {len(dataframes['payments']):,} registros â†’ {len(payments_agg):,} pedidos Ãºnicos\")\n",
        "\n",
        "# AgregaciÃ³n de REVIEWS: Tomar la primera review por pedido\n",
        "# Nota: En caso de mÃºltiples reviews, priorizamos la primera cronolÃ³gicamente\n",
        "reviews_unique = dataframes['reviews'].sort_values('review_creation_date').groupby('order_id').first().reset_index()\n",
        "reviews_unique = reviews_unique[['order_id', 'review_score']]\n",
        "\n",
        "print(f\"âœ… Reviews procesado:  {len(dataframes['reviews']):,} registros â†’ {len(reviews_unique):,} pedidos Ãºnicos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”— Iniciando secuencia de joins...\n",
            "\n",
            "âœ… JOIN 1: Orders + Customers        | Filas: 96,478\n",
            "âœ… JOIN 2: + Order Items             | Filas: 110,197\n",
            "âœ… JOIN 3: + Products                | Filas: 110,197\n",
            "âœ… JOIN 4: + Reviews                 | Filas: 110,197\n",
            "âœ… JOIN 5: + Payments                | Filas: 110,197\n",
            "\n",
            "ğŸ‰ Tabla maestra construida con Ã©xito!\n"
          ]
        }
      ],
      "source": [
        "# PASO 5.2: Secuencia de Joins\n",
        "print(\"\\nğŸ”— Iniciando secuencia de joins...\\n\")\n",
        "\n",
        "# JOIN 1: Orders + Customers (datos demogrÃ¡ficos)\n",
        "tabla_master = orders_delivered.merge(\n",
        "    dataframes['customers'],\n",
        "    on='customer_id',\n",
        "    how='left'\n",
        ")\n",
        "print(f\"âœ… JOIN 1: Orders + Customers        | Filas: {len(tabla_master):,}\")\n",
        "\n",
        "# JOIN 2: + Order Items (productos en el pedido)\n",
        "tabla_master = tabla_master.merge(\n",
        "    dataframes['order_items'],\n",
        "    on='order_id',\n",
        "    how='left'\n",
        ")\n",
        "print(f\"âœ… JOIN 2: + Order Items             | Filas: {len(tabla_master):,}\")\n",
        "\n",
        "# JOIN 3: + Products (informaciÃ³n de categorÃ­a)\n",
        "tabla_master = tabla_master.merge(\n",
        "    dataframes['products'][['product_id', 'product_category_name']],\n",
        "    on='product_id',\n",
        "    how='left'\n",
        ")\n",
        "print(f\"âœ… JOIN 3: + Products                | Filas: {len(tabla_master):,}\")\n",
        "\n",
        "# JOIN 4: + Reviews (satisfacciÃ³n del cliente)\n",
        "tabla_master = tabla_master.merge(\n",
        "    reviews_unique,\n",
        "    on='order_id',\n",
        "    how='left'\n",
        ")\n",
        "print(f\"âœ… JOIN 4: + Reviews                 | Filas: {len(tabla_master):,}\")\n",
        "\n",
        "# JOIN 5: + Payments (mÃ©todo de pago)\n",
        "tabla_master = tabla_master.merge(\n",
        "    payments_agg[['order_id', 'payment_type']],\n",
        "    on='order_id',\n",
        "    how='left'\n",
        ")\n",
        "print(f\"âœ… JOIN 5: + Payments                | Filas: {len(tabla_master):,}\")\n",
        "\n",
        "print(f\"\\nğŸ‰ Tabla maestra construida con Ã©xito!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ¨ Paso 6: SelecciÃ³n, Renombrado y Transformaciones Finales\n",
        "\n",
        "Estandarizamos la estructura final y aplicamos transformaciones:\n",
        "1. **SelecciÃ³n de columnas** relevantes del negocio\n",
        "2. **Formato de fecha**: DD-MM-YYYY (sin hora)\n",
        "3. **NumeraciÃ³n secuencial**: Columna order_number basada en fecha de compra\n",
        "4. **ExpansiÃ³n de estados**: Nombres completos en lugar de siglas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Columnas seleccionadas y renombradas\n",
            "\n",
            "ğŸ”§ Aplicando transformaciones finales...\n",
            "\n",
            "ğŸ“… 1. Convirtiendo formato de fecha...\n",
            "   âœ… Fecha formateada a DD-MM-YYYY\n",
            "\n",
            "ğŸ”¢ 2. Creando numeraciÃ³n secuencial de Ã³rdenes...\n",
            "   âœ… 96,478 Ã³rdenes numeradas (1 a 96,478)\n",
            "\n",
            "ğŸ—ºï¸  3. Expandiendo nombres de estados...\n",
            "   âœ… 27 estados convertidos\n",
            "\n",
            "âœ… Transformaciones completadas\n",
            "\n",
            "ğŸ“‹ Estructura final:\n",
            "order_number                 int64\n",
            "order_id                    object\n",
            "product_id                  object\n",
            "price                      float64\n",
            "product_category_name       object\n",
            "order_purchase_datetime     object\n",
            "orders_status               object\n",
            "orders_customer_id          object\n",
            "customer_unique_id          object\n",
            "customer_state              object\n",
            "review_score               float64\n",
            "payment_type                object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# SelecciÃ³n de columnas relevantes segÃºn estructura objetivo\n",
        "columnas_finales = [\n",
        "    'order_id',\n",
        "    'product_id',\n",
        "    'price',\n",
        "    'product_category_name',\n",
        "    'order_purchase_timestamp',      # SerÃ¡ renombrado\n",
        "    'order_status',                  # SerÃ¡ renombrado\n",
        "    'customer_id',                   # SerÃ¡ renombrado\n",
        "    'customer_unique_id',\n",
        "    'customer_state',\n",
        "    'review_score',\n",
        "    'payment_type'\n",
        "]\n",
        "\n",
        "# Crear dataset final con columnas seleccionadas\n",
        "tabla_final = tabla_master[columnas_finales].copy()\n",
        "\n",
        "# Renombrado para coincidir con nomenclatura de tabla_principal\n",
        "tabla_final.rename(columns={\n",
        "    'order_purchase_timestamp': 'order_purchase_datetime',\n",
        "    'order_status': 'orders_status',\n",
        "    'customer_id': 'orders_customer_id'\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"âœ… Columnas seleccionadas y renombradas\")\n",
        "\n",
        "# TRANSFORMACIONES ADICIONALES\n",
        "print(\"\\nğŸ”§ Aplicando transformaciones finales...\")\n",
        "\n",
        "# TRANSFORMACIÃ“N 1: Formato de Fecha (dÃ­a-mes-aÃ±o sin hora)\n",
        "print(\"\\nğŸ“… 1. Convirtiendo formato de fecha...\")\n",
        "tabla_final['order_purchase_datetime'] = pd.to_datetime(tabla_final['order_purchase_datetime'])\n",
        "tabla_final['order_purchase_datetime'] = tabla_final['order_purchase_datetime'].dt.strftime('%d-%m-%Y')\n",
        "print(f\"   âœ… Fecha formateada a DD-MM-YYYY\")\n",
        "\n",
        "# TRANSFORMACIÃ“N 2: Crear columna order_number secuencial\n",
        "print(\"\\nğŸ”¢ 2. Creando numeraciÃ³n secuencial de Ã³rdenes...\")\n",
        "temp_datetime = pd.to_datetime(tabla_final['order_purchase_datetime'], format='%d-%m-%Y')\n",
        "order_fecha = tabla_final[['order_id']].copy()\n",
        "order_fecha['fecha_temp'] = temp_datetime\n",
        "order_ranking = order_fecha.drop_duplicates('order_id').sort_values('fecha_temp')\n",
        "order_ranking['order_number'] = range(1, len(order_ranking) + 1)\n",
        "order_map = dict(zip(order_ranking['order_id'], order_ranking['order_number']))\n",
        "tabla_final['order_number'] = tabla_final['order_id'].map(order_map)\n",
        "print(f\"   âœ… {len(order_ranking):,} Ã³rdenes numeradas (1 a {len(order_ranking):,})\")\n",
        "\n",
        "# TRANSFORMACIÃ“N 3: Expandir nombres de estados brasileÃ±os\n",
        "print(\"\\nğŸ—ºï¸  3. Expandiendo nombres de estados...\")\n",
        "estados_brasil = {\n",
        "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapa', 'AM': 'Amazonas',\n",
        "    'BA': 'Bahia', 'CE': 'Ceara', 'DF': 'Distrito Federal',\n",
        "    'ES': 'Espirito Santo', 'GO': 'Goias', 'MA': 'Maranhao',\n",
        "    'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais',\n",
        "    'PA': 'Para', 'PB': 'Paraiba', 'PR': 'Parana', 'PE': 'Pernambuco',\n",
        "    'PI': 'Piaui', 'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte',\n",
        "    'RS': 'Rio Grande do Sul', 'RO': 'Rondonia', 'RR': 'Roraima',\n",
        "    'SC': 'Santa Catarina', 'SP': 'Sao Paulo', 'SE': 'Sergipe', 'TO': 'Tocantins'\n",
        "}\n",
        "tabla_final['customer_state'] = tabla_final['customer_state'].map(estados_brasil)\n",
        "print(f\"   âœ… {tabla_final['customer_state'].nunique()} estados convertidos\")\n",
        "\n",
        "# Reordenar columnas para que order_number estÃ© al inicio\n",
        "columnas_ordenadas = ['order_number'] + [col for col in tabla_final.columns if col != 'order_number']\n",
        "tabla_final = tabla_final[columnas_ordenadas]\n",
        "\n",
        "print(\"\\nâœ… Transformaciones completadas\")\n",
        "print(f\"\\nğŸ“‹ Estructura final:\")\n",
        "print(tabla_final.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§¹ Paso 7: ValidaciÃ³n de Calidad\n",
        "\n",
        "Verificamos la calidad del dataset final con todas las transformaciones aplicadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ” VALIDACIÃ“N DE CALIDAD - DATASET FINAL\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Dimensiones: 110,197 filas Ã— 12 columnas\n",
            "ğŸ’¾ TamaÃ±o en memoria: 75.53 MB\n",
            "\n",
            "ğŸ” AnÃ¡lisis de completitud:\n",
            "   âœ… order_number                   | Nulos: 0 (0.0%)\n",
            "   âœ… order_id                       | Nulos: 0 (0.0%)\n",
            "   âœ… product_id                     | Nulos: 0 (0.0%)\n",
            "   âœ… price                          | Nulos: 0 (0.0%)\n",
            "   âš ï¸ product_category_name          | Nulos: 1,537 (1.4%)\n",
            "   âœ… order_purchase_datetime        | Nulos: 0 (0.0%)\n",
            "   âœ… orders_status                  | Nulos: 0 (0.0%)\n",
            "   âœ… orders_customer_id             | Nulos: 0 (0.0%)\n",
            "   âœ… customer_unique_id             | Nulos: 0 (0.0%)\n",
            "   âœ… customer_state                 | Nulos: 0 (0.0%)\n",
            "   âš ï¸ review_score                   | Nulos: 827 (0.8%)\n",
            "   âš ï¸ payment_type                   | Nulos: 3 (0.0%)\n",
            "\n",
            "âœ… Status Ãºnicos en el dataset: ['delivered']\n",
            "âœ… Total de pedidos delivered: 110,197\n",
            "\n",
            "ğŸ“ˆ Insights del Dataset:\n",
            "   ğŸ›’ Productos Ãºnicos:  32,216\n",
            "   ğŸ‘¥ Clientes Ãºnicos:   93,358\n",
            "   ğŸ“¦ Pedidos Ãºnicos:    96,478\n",
            "   ğŸ—‚ï¸  CategorÃ­as:        73\n",
            "   ğŸŒ Estados:           27\n",
            "   â­ Review promedio:   4.08/5.0\n"
          ]
        }
      ],
      "source": [
        "# Reporte de calidad del dataset final\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ” VALIDACIÃ“N DE CALIDAD - DATASET FINAL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nğŸ“Š Dimensiones: {tabla_final.shape[0]:,} filas Ã— {tabla_final.shape[1]} columnas\")\n",
        "print(f\"ğŸ’¾ TamaÃ±o en memoria: {tabla_final.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Verificar valores nulos\n",
        "print(f\"\\nğŸ” AnÃ¡lisis de completitud:\")\n",
        "nulos_finales = tabla_final.isnull().sum()\n",
        "for col in tabla_final.columns:\n",
        "    nulos = nulos_finales[col]\n",
        "    pct_nulos = (nulos / len(tabla_final)) * 100\n",
        "    status = \"âœ…\" if nulos == 0 else \"âš ï¸\"\n",
        "    print(f\"   {status} {col:30} | Nulos: {nulos:,} ({pct_nulos:.1f}%)\")\n",
        "\n",
        "# Verificar que todos los registros son 'delivered'\n",
        "print(f\"\\nâœ… Status Ãºnicos en el dataset: {tabla_final['orders_status'].unique()}\")\n",
        "print(f\"âœ… Total de pedidos delivered: {len(tabla_final):,}\")\n",
        "\n",
        "# EstadÃ­sticas descriptivas clave\n",
        "print(f\"\\nğŸ“ˆ Insights del Dataset:\")\n",
        "print(f\"   ğŸ›’ Productos Ãºnicos:  {tabla_final['product_id'].nunique():,}\")\n",
        "print(f\"   ğŸ‘¥ Clientes Ãºnicos:   {tabla_final['customer_unique_id'].nunique():,}\")\n",
        "print(f\"   ğŸ“¦ Pedidos Ãºnicos:    {tabla_final['order_id'].nunique():,}\")\n",
        "print(f\"   ğŸ—‚ï¸  CategorÃ­as:        {tabla_final['product_category_name'].nunique():,}\")\n",
        "print(f\"   ğŸŒ Estados:           {tabla_final['customer_state'].nunique():,}\")\n",
        "print(f\"   â­ Review promedio:   {tabla_final['review_score'].mean():.2f}/5.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¾ Paso 8: LOAD - ExportaciÃ³n del Dataset Final\n",
        "\n",
        "Guardamos el dataset consolidado y transformado en formato CSV para anÃ¡lisis posteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ’¾ EXPORTACIÃ“N EXITOSA\n",
            "================================================================================\n",
            "\n",
            "âœ… Archivo guardado: tabla_principal_etl.csv\n",
            "ğŸ“Š Registros exportados: 110,197\n",
            "ğŸ“ Columnas totales: 12\n",
            "\n",
            "ğŸ¨ Transformaciones Aplicadas:\n",
            "   âœ… Fechas en formato: DD-MM-YYYY (sin hora)\n",
            "   âœ… Orden secuencial: NumeraciÃ³n 1 a 96,478\n",
            "   âœ… Estados: Nombres completos (sin abreviaciones)\n",
            "\n",
            "ğŸ‘€ Vista previa (primeras 10 filas con columnas clave):\n",
            " order_number                         order_id order_purchase_datetime      customer_state product_category_name  price\n",
            "        26662 e481f51cbdc54678b7cc49136f2d6af7              02-10-2017           Sao Paulo utilidades_domesticas  29.99\n",
            "        88456 53cdb2fc8bc7dce0b6741e2150273451              24-07-2018               Bahia            perfumaria 118.70\n",
            "        92361 47770eb9100c2d0c44946d9cf07ec65d              08-08-2018               Goias            automotivo 159.90\n",
            "        33657 949d5b44dbf5de918fe9c16f97b45f8a              18-11-2017 Rio Grande do Norte              pet_shop  45.00\n",
            "        53505 ad21c59c0840e6cb83a9ceb5573f8159              13-02-2018           Sao Paulo             papelaria  19.90\n",
            "        15110 a4591c265e18cb1dcee52889e2d8acc3              09-07-2017              Parana            automotivo 147.90\n",
            "         9311 6514b8ad8028c9f2cc2374ded245783f              16-05-2017      Rio de Janeiro            automotivo  59.99\n",
            "          577 76c6e866289321a7c93b82b54852dc33              23-01-2017   Rio Grande do Sul      moveis_decoracao  19.90\n",
            "        17710 e69bfb5eb88e0ed6a785585b27e16dbf              29-07-2017           Sao Paulo     moveis_escritorio 149.99\n",
            "         9305 e6ce16cb79ec1d90b1da9085a6118aeb              16-05-2017      Rio de Janeiro    ferramentas_jardim  99.00\n",
            "\n",
            "ğŸ“ˆ EstadÃ­sticas del Dataset Final:\n",
            "   ğŸ”¢ Ã“rdenes Ãºnicas: 96,478\n",
            "   ğŸ“… Rango de fechas: 01-01-2018 a 31-12-2017\n",
            "   ğŸ—ºï¸  Estados Ãºnicos: 27\n"
          ]
        }
      ],
      "source": [
        "# ExportaciÃ³n a CSV con todas las transformaciones aplicadas\n",
        "nombre_archivo = 'tabla_principal_etl.csv'\n",
        "\n",
        "try:\n",
        "    tabla_final.to_csv(nombre_archivo, index=False)\n",
        "    print(\"=\"*80)\n",
        "    print(\"ğŸ’¾ EXPORTACIÃ“N EXITOSA\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nâœ… Archivo guardado: {nombre_archivo}\")\n",
        "    print(f\"ğŸ“Š Registros exportados: {len(tabla_final):,}\")\n",
        "    print(f\"ğŸ“ Columnas totales: {len(tabla_final.columns)}\")\n",
        "    \n",
        "    # InformaciÃ³n sobre las transformaciones aplicadas\n",
        "    print(f\"\\nğŸ¨ Transformaciones Aplicadas:\")\n",
        "    print(f\"   âœ… Fechas en formato: DD-MM-YYYY (sin hora)\")\n",
        "    print(f\"   âœ… Orden secuencial: NumeraciÃ³n 1 a {tabla_final['order_number'].max():,}\")\n",
        "    print(f\"   âœ… Estados: Nombres completos (sin abreviaciones)\")\n",
        "    \n",
        "    # Vista previa enfocada en las transformaciones\n",
        "    print(f\"\\nğŸ‘€ Vista previa (primeras 10 filas con columnas clave):\")\n",
        "    columnas_preview = ['order_number', 'order_id', 'order_purchase_datetime', \n",
        "                        'customer_state', 'product_category_name', 'price']\n",
        "    print(tabla_final[columnas_preview].head(10).to_string(index=False))\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ EstadÃ­sticas del Dataset Final:\")\n",
        "    print(f\"   ğŸ”¢ Ã“rdenes Ãºnicas: {tabla_final['order_number'].nunique():,}\")\n",
        "    print(f\"   ğŸ“… Rango de fechas: {tabla_final['order_purchase_datetime'].min()} a {tabla_final['order_purchase_datetime'].max()}\")\n",
        "    print(f\"   ğŸ—ºï¸  Estados Ãºnicos: {tabla_final['customer_state'].nunique()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ ERROR al guardar el archivo: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Paso 9: Storytelling con Datos - Insights EstratÃ©gicos\n",
        "\n",
        "**Del Dato a la DecisiÃ³n:** Exploramos patrones que transforman informaciÃ³n en acciÃ³n.\n",
        "\n",
        "### ğŸ¯ Framework de AnÃ¡lisis\n",
        "1. **Â¿QuÃ© pasÃ³?** (Descriptivo)\n",
        "2. **Â¿Por quÃ© pasÃ³?** (DiagnÃ³stico)\n",
        "3. **Â¿QuÃ© debemos hacer?** (Prescriptivo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ“Š ANÃLISIS ESTRATÃ‰GICO - INSIGHTS ACCIONABLES\n",
            "================================================================================\n",
            "\n",
            "ğŸ† TOP 10 CATEGORÃAS POR VOLUMEN DE VENTAS\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            " 1. cama_mesa_banho                | 10,953 pedidos ( 9.9%)\n",
            " 2. beleza_saude                   | 9,465 pedidos ( 8.6%)\n",
            " 3. esporte_lazer                  | 8,431 pedidos ( 7.7%)\n",
            " 4. moveis_decoracao               | 8,160 pedidos ( 7.4%)\n",
            " 5. informatica_acessorios         | 7,644 pedidos ( 6.9%)\n",
            " 6. utilidades_domesticas          | 6,795 pedidos ( 6.2%)\n",
            " 7. relogios_presentes             | 5,859 pedidos ( 5.3%)\n",
            " 8. telefonia                      | 4,430 pedidos ( 4.0%)\n",
            " 9. ferramentas_jardim             | 4,268 pedidos ( 3.9%)\n",
            "10. automotivo                     | 4,140 pedidos ( 3.8%)\n",
            "\n",
            "ğŸ’¡ RecomendaciÃ³n: Estas categorÃ­as son el corazÃ³n del negocio.\n",
            "   â†’ Priorizar stock y campaÃ±as de marketing en estas lÃ­neas.\n",
            "   â†’ Analizar quÃ© hace exitosas estas categorÃ­as para replicar en otras.\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"ğŸ“Š ANÃLISIS ESTRATÃ‰GICO - INSIGHTS ACCIONABLES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# INSIGHT 1: CategorÃ­as Top por Volumen\n",
        "print(\"\\nğŸ† TOP 10 CATEGORÃAS POR VOLUMEN DE VENTAS\")\n",
        "print(\"â”€\"*80)\n",
        "top_categorias = tabla_final['product_category_name'].value_counts().head(10)\n",
        "for i, (cat, count) in enumerate(top_categorias.items(), 1):\n",
        "    pct = (count / len(tabla_final)) * 100\n",
        "    print(f\"{i:2}. {cat:30} | {count:5,} pedidos ({pct:4.1f}%)\")\n",
        "\n",
        "print(\"\\nğŸ’¡ RecomendaciÃ³n: Estas categorÃ­as son el corazÃ³n del negocio.\")\n",
        "print(\"   â†’ Priorizar stock y campaÃ±as de marketing en estas lÃ­neas.\")\n",
        "print(\"   â†’ Analizar quÃ© hace exitosas estas categorÃ­as para replicar en otras.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â­ SATISFACCIÃ“N DEL CLIENTE (Review Score) POR CATEGORÃA\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "ğŸŒŸ TOP 5 CATEGORÃAS CON MAYOR SATISFACCIÃ“N (min. 50 reviews):\n",
            "1. livros_importados                   | â­ 4.51 | ğŸ“Š 57 reviews\n",
            "2. livros_interesse_geral              | â­ 4.51 | ğŸ“Š 533 reviews\n",
            "3. construcao_ferramentas_ferramentas  | â­ 4.44 | ğŸ“Š 99 reviews\n",
            "4. portateis_casa_forno_e_cafe         | â­ 4.44 | ğŸ“Š 73 reviews\n",
            "5. livros_tecnicos                     | â­ 4.39 | ğŸ“Š 262 reviews\n",
            "\n",
            "âš ï¸  BOTTOM 5 CATEGORÃAS CON MENOR SATISFACCIÃ“N:\n",
            "1. casa_conforto                       | â­ 3.86 | ğŸ“Š 427 reviews\n",
            "2. audio                               | â­ 3.84 | ğŸ“Š 358 reviews\n",
            "3. fashion_roupa_masculina             | â­ 3.76 | ğŸ“Š 124 reviews\n",
            "4. telefonia_fixa                      | â­ 3.76 | ğŸ“Š 252 reviews\n",
            "5. moveis_escritorio                   | â­ 3.51 | ğŸ“Š 1654 reviews\n",
            "\n",
            "ğŸ’¡ RecomendaciÃ³n: \n",
            "   â†’ Investigar causas de baja satisfacciÃ³n (calidad, envÃ­o, descripciÃ³n).\n",
            "   â†’ Implementar controles de calidad mÃ¡s estrictos en categorÃ­as problemÃ¡ticas.\n",
            "   â†’ Usar categorÃ­as top como benchmarks de excelencia operativa.\n"
          ]
        }
      ],
      "source": [
        "# INSIGHT 2: SatisfacciÃ³n del Cliente por CategorÃ­a\n",
        "print(\"\\nâ­ SATISFACCIÃ“N DEL CLIENTE (Review Score) POR CATEGORÃA\")\n",
        "print(\"â”€\"*80)\n",
        "\n",
        "satisfaccion = tabla_final.groupby('product_category_name').agg({\n",
        "    'review_score': ['mean', 'count']\n",
        "}).round(2)\n",
        "\n",
        "satisfaccion.columns = ['review_promedio', 'num_reviews']\n",
        "satisfaccion = satisfaccion[satisfaccion['num_reviews'] >= 50]  # Filtrar categorÃ­as con suficientes datos\n",
        "satisfaccion = satisfaccion.sort_values('review_promedio', ascending=False)\n",
        "\n",
        "print(\"\\nğŸŒŸ TOP 5 CATEGORÃAS CON MAYOR SATISFACCIÃ“N (min. 50 reviews):\")\n",
        "for i, (cat, row) in enumerate(satisfaccion.head().iterrows(), 1):\n",
        "    print(f\"{i}. {cat:35} | â­ {row['review_promedio']:.2f} | ğŸ“Š {int(row['num_reviews'])} reviews\")\n",
        "\n",
        "print(\"\\nâš ï¸  BOTTOM 5 CATEGORÃAS CON MENOR SATISFACCIÃ“N:\")\n",
        "for i, (cat, row) in enumerate(satisfaccion.tail().iterrows(), 1):\n",
        "    print(f\"{i}. {cat:35} | â­ {row['review_promedio']:.2f} | ğŸ“Š {int(row['num_reviews'])} reviews\")\n",
        "\n",
        "print(\"\\nğŸ’¡ RecomendaciÃ³n: \")\n",
        "print(\"   â†’ Investigar causas de baja satisfacciÃ³n (calidad, envÃ­o, descripciÃ³n).\")\n",
        "print(\"   â†’ Implementar controles de calidad mÃ¡s estrictos en categorÃ­as problemÃ¡ticas.\")\n",
        "print(\"   â†’ Usar categorÃ­as top como benchmarks de excelencia operativa.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’³ MÃ‰TODOS DE PAGO MÃS POPULARES\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   credit_card          | 84,154 transacciones (76.4%)\n",
            "   boleto               | 22,362 transacciones (20.3%)\n",
            "   voucher              | 2,026 transacciones (1.8%)\n",
            "   debit_card           | 1,652 transacciones (1.5%)\n",
            "\n",
            "ğŸ—ºï¸  PREFERENCIA DE PAGO POR ESTADO (Top 5 estados):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Sao Paulo | Prefiere: credit_card     (76.3% de 46,448 pedidos)\n",
            "   Rio de Janeiro | Prefiere: credit_card     (79.1% de 14,143 pedidos)\n",
            "   Minas Gerais | Prefiere: credit_card     (76.8% de 12,916 pedidos)\n",
            "   Rio Grande do Sul | Prefiere: credit_card     (71.8% de 6,134 pedidos)\n",
            "   Parana | Prefiere: credit_card     (74.5% de 5,649 pedidos)\n",
            "\n",
            "ğŸ’¡ RecomendaciÃ³n:\n",
            "   â†’ Optimizar proceso de checkout para el mÃ©todo de pago dominante.\n",
            "   â†’ Considerar promociones especÃ­ficas por mÃ©todo de pago en cada regiÃ³n.\n"
          ]
        }
      ],
      "source": [
        "# INSIGHT 3: Preferencias de Pago por Estado\n",
        "print(\"\\nğŸ’³ MÃ‰TODOS DE PAGO MÃS POPULARES\")\n",
        "print(\"â”€\"*80)\n",
        "\n",
        "pagos_total = tabla_final['payment_type'].value_counts()\n",
        "for metodo, count in pagos_total.items():\n",
        "    pct = (count / len(tabla_final)) * 100\n",
        "    print(f\"   {metodo:20} | {count:,} transacciones ({pct:.1f}%)\")\n",
        "\n",
        "# AnÃ¡lisis por estado (top 5 estados)\n",
        "top_estados = tabla_final['customer_state'].value_counts().head(5).index\n",
        "\n",
        "print(\"\\nğŸ—ºï¸  PREFERENCIA DE PAGO POR ESTADO (Top 5 estados):\")\n",
        "for estado in top_estados:\n",
        "    df_estado = tabla_final[tabla_final['customer_state'] == estado]\n",
        "    metodo_preferido = df_estado['payment_type'].mode()[0]\n",
        "    pct_metodo = (df_estado['payment_type'] == metodo_preferido).sum() / len(df_estado) * 100\n",
        "    print(f\"   {estado:5} | Prefiere: {metodo_preferido:15} ({pct_metodo:.1f}% de {len(df_estado):,} pedidos)\")\n",
        "\n",
        "print(\"\\nğŸ’¡ RecomendaciÃ³n:\")\n",
        "print(\"   â†’ Optimizar proceso de checkout para el mÃ©todo de pago dominante.\")\n",
        "print(\"   â†’ Considerar promociones especÃ­ficas por mÃ©todo de pago en cada regiÃ³n.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ’° RELACIÃ“N PRECIO - SATISFACCIÃ“N DEL CLIENTE\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Segmento de Precio | Review Promedio | NÃºmero de Pedidos\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   R$ 0-50       | â­ 4.08          | 38,530 pedidos\n",
            "   R$ 50-100     | â­ 4.06          | 32,376 pedidos\n",
            "   R$ 100-200    | â­ 4.11          | 26,356 pedidos\n",
            "   R$ 200-500    | â­ 4.11          | 9,845 pedidos\n",
            "   R$ 500+       | â­ 4.10          | 3,090 pedidos\n",
            "\n",
            "ğŸ“Š CorrelaciÃ³n precio-satisfacciÃ³n: 0.003\n",
            "\n",
            "ğŸ’¡ Insight: El precio tiene POCA relaciÃ³n con la satisfacciÃ³n del cliente.\n",
            "   â†’ La calidad del servicio y producto importa mÃ¡s que el precio.\n",
            "   â†’ Enfocarse en mejorar experiencia de entrega y calidad de producto.\n"
          ]
        }
      ],
      "source": [
        "# INSIGHT 4: RelaciÃ³n Precio - SatisfacciÃ³n\n",
        "print(\"\\nğŸ’° RELACIÃ“N PRECIO - SATISFACCIÃ“N DEL CLIENTE\")\n",
        "print(\"â”€\"*80)\n",
        "\n",
        "# Crear segmentos de precio\n",
        "tabla_final['precio_segmento'] = pd.cut(\n",
        "    tabla_final['price'], \n",
        "    bins=[0, 50, 100, 200, 500, float('inf')],\n",
        "    labels=['0-50', '50-100', '100-200', '200-500', '500+']\n",
        ")\n",
        "\n",
        "precio_satisfaccion = tabla_final.groupby('precio_segmento').agg({\n",
        "    'review_score': 'mean',\n",
        "    'order_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "precio_satisfaccion.columns = ['review_promedio', 'num_pedidos']\n",
        "\n",
        "print(\"\\nSegmento de Precio | Review Promedio | NÃºmero de Pedidos\")\n",
        "print(\"â”€\"*80)\n",
        "for segmento, row in precio_satisfaccion.iterrows():\n",
        "    print(f\"   R$ {segmento:10} | â­ {row['review_promedio']:.2f}          | {int(row['num_pedidos']):,} pedidos\")\n",
        "\n",
        "correlacion = tabla_final[['price', 'review_score']].corr().iloc[0, 1]\n",
        "print(f\"\\nğŸ“Š CorrelaciÃ³n precio-satisfacciÃ³n: {correlacion:.3f}\")\n",
        "\n",
        "if abs(correlacion) < 0.1:\n",
        "    print(\"\\nğŸ’¡ Insight: El precio tiene POCA relaciÃ³n con la satisfacciÃ³n del cliente.\")\n",
        "    print(\"   â†’ La calidad del servicio y producto importa mÃ¡s que el precio.\")\n",
        "    print(\"   â†’ Enfocarse en mejorar experiencia de entrega y calidad de producto.\")\n",
        "elif correlacion > 0:\n",
        "    print(\"\\nğŸ’¡ Insight: A mayor precio, MAYOR satisfacciÃ³n.\")\n",
        "    print(\"   â†’ Los clientes asocian precio alto con mejor calidad.\")\n",
        "    print(\"   â†’ Oportunidad de expandir lÃ­neas premium con valor aÃ±adido.\")\n",
        "else:\n",
        "    print(\"\\nğŸ’¡ Insight: A mayor precio, MENOR satisfacciÃ³n.\")\n",
        "    print(\"   â†’ Revisar si los productos premium cumplen expectativas.\")\n",
        "    print(\"   â†’ Ajustar estrategia de pricing o mejorar propuesta de valor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ—ºï¸  CONCENTRACIÃ“N GEOGRÃFICA DEL NEGOCIO\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Top 10 Estados por Volumen de Pedidos:\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            " 1. Sao Paulo | 46,448 pedidos |  42.1% | Acumulado:  42.1%\n",
            " 2. Rio de Janeiro | 14,143 pedidos |  12.8% | Acumulado:  55.0%\n",
            " 3. Minas Gerais | 12,916 pedidos |  11.7% | Acumulado:  66.7%\n",
            " 4. Rio Grande do Sul |  6,134 pedidos |   5.6% | Acumulado:  72.3%\n",
            " 5. Parana |  5,649 pedidos |   5.1% | Acumulado:  77.4%\n",
            " 6. Santa Catarina |  4,097 pedidos |   3.7% | Acumulado:  81.1%\n",
            " 7. Bahia |  3,683 pedidos |   3.3% | Acumulado:  84.5%\n",
            " 8. Distrito Federal |  2,355 pedidos |   2.1% | Acumulado:  86.6%\n",
            " 9. Goias |  2,277 pedidos |   2.1% | Acumulado:  88.7%\n",
            "10. Espirito Santo |  2,225 pedidos |   2.0% | Acumulado:  90.7%\n",
            "\n",
            "ğŸ“Š Los 3 estados principales concentran el 66.7% del negocio\n",
            "\n",
            "ğŸ’¡ RecomendaciÃ³n:\n",
            "   âš ï¸  ALTA CONCENTRACIÃ“N GEOGRÃFICA - Riesgo de dependencia regional.\n",
            "   â†’ Desarrollar estrategia de expansiÃ³n a estados subrepresentados.\n",
            "   â†’ Investigar barreras de entrada en mercados desatendidos.\n"
          ]
        }
      ],
      "source": [
        "# INSIGHT 5: DistribuciÃ³n GeogrÃ¡fica\n",
        "print(\"\\nğŸ—ºï¸  CONCENTRACIÃ“N GEOGRÃFICA DEL NEGOCIO\")\n",
        "print(\"â”€\"*80)\n",
        "\n",
        "dist_geografica = tabla_final['customer_state'].value_counts().head(10)\n",
        "total_pedidos = len(tabla_final)\n",
        "\n",
        "print(\"\\nTop 10 Estados por Volumen de Pedidos:\")\n",
        "print(\"â”€\"*80)\n",
        "acumulado = 0\n",
        "for i, (estado, count) in enumerate(dist_geografica.items(), 1):\n",
        "    pct = (count / total_pedidos) * 100\n",
        "    acumulado += pct\n",
        "    print(f\"{i:2}. {estado:5} | {count:6,} pedidos | {pct:5.1f}% | Acumulado: {acumulado:5.1f}%\")\n",
        "\n",
        "top3_pct = (dist_geografica.head(3).sum() / total_pedidos) * 100\n",
        "print(f\"\\nğŸ“Š Los 3 estados principales concentran el {top3_pct:.1f}% del negocio\")\n",
        "\n",
        "print(\"\\nğŸ’¡ RecomendaciÃ³n:\")\n",
        "if top3_pct > 60:\n",
        "    print(\"   âš ï¸  ALTA CONCENTRACIÃ“N GEOGRÃFICA - Riesgo de dependencia regional.\")\n",
        "    print(\"   â†’ Desarrollar estrategia de expansiÃ³n a estados subrepresentados.\")\n",
        "    print(\"   â†’ Investigar barreras de entrada en mercados desatendidos.\")\n",
        "else:\n",
        "    print(\"   âœ… DistribuciÃ³n geogrÃ¡fica saludable.\")\n",
        "    print(\"   â†’ Mantener estrategias de penetraciÃ³n en mercados secundarios.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Paso 10: Conclusiones y PrÃ³ximos Pasos\n",
        "\n",
        "### âœ… Lo que Logramos\n",
        "\n",
        "1. **Pipeline ETL Robusto**: Integramos 6 fuentes de datos en una tabla analÃ­tica consolidada\n",
        "2. **Calidad de Datos**: Filtrado preciso de pedidos delivered con validaciones completas\n",
        "3. **Insights Accionables**: Identificamos oportunidades estratÃ©gicas basadas en datos\n",
        "\n",
        "### ğŸ”® Siguientes AnÃ¡lisis Recomendados\n",
        "\n",
        "**AnÃ¡lisis de RetenciÃ³n:**\n",
        "- Â¿CuÃ¡ntos clientes son recurrentes vs. nuevos?\n",
        "- Â¿QuÃ© categorÃ­as generan mayor lealtad?\n",
        "\n",
        "**AnÃ¡lisis Temporal:**\n",
        "- Tendencias de ventas por mes/dÃ­a de la semana\n",
        "- Estacionalidad por categorÃ­a de producto\n",
        "\n",
        "**AnÃ¡lisis Predictivo:**\n",
        "- Modelar probabilidad de review positivo (score >= 4)\n",
        "- Predecir categorÃ­as con mayor potencial de crecimiento\n",
        "\n",
        "**OptimizaciÃ³n Operativa:**\n",
        "- AnÃ¡lisis de tiempos de entrega por regiÃ³n\n",
        "- Identificar cuellos de botella en la cadena logÃ­stica\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“š Recursos y DocumentaciÃ³n\n",
        "\n",
        "**Archivos Generados:**\n",
        "- `tabla_principal_etl.csv`: Dataset consolidado listo para anÃ¡lisis\n",
        "\n",
        "**Dependencias:**\n",
        "- pandas >= 1.3.0\n",
        "- numpy >= 1.21.0\n",
        "\n",
        "**Nota TÃ©cnica:** Este notebook estÃ¡ optimizado para datasets de tamaÃ±o mediano (< 10M registros). Para volÃºmenes mayores, considerar:\n",
        "- Procesamiento por chunks con `pd.read_csv(chunksize=...)`\n",
        "- Uso de Dask o PySpark para procesamiento distribuido\n",
        "- Almacenamiento en formato Parquet para mayor eficiencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ‰ PROCESO ETL COMPLETADO CON Ã‰XITO\n",
            "================================================================================\n",
            "\n",
            "âœ… Dataset final exportado: tabla_principal_etl.csv\n",
            "âœ… Total de registros: 110,197\n",
            "âœ… Columnas incluidas: 13\n",
            "âœ… Status verificado: 100% delivered\n",
            "\n",
            "ğŸ’¾ El archivo estÃ¡ listo para anÃ¡lisis avanzados, visualizaciones y modelado predictivo.\n",
            "\n",
            "ğŸ“… Proceso finalizado: 2026-01-21 14:09:53\n"
          ]
        }
      ],
      "source": [
        "# Resumen final de ejecuciÃ³n\n",
        "print(\"=\"*80)\n",
        "print(\"ğŸ‰ PROCESO ETL COMPLETADO CON Ã‰XITO\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nâœ… Dataset final exportado: tabla_principal_etl.csv\")\n",
        "print(f\"âœ… Total de registros: {len(tabla_final):,}\")\n",
        "print(f\"âœ… Columnas incluidas: {len(tabla_final.columns)}\")\n",
        "print(f\"âœ… Status verificado: 100% delivered\")\n",
        "print(f\"\\nğŸ’¾ El archivo estÃ¡ listo para anÃ¡lisis avanzados, visualizaciones y modelado predictivo.\")\n",
        "print(f\"\\nğŸ“… Proceso finalizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
